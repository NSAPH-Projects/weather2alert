import os
import pandas as pd
import hydra


configfile: "conf/snakemake.yaml"  # Path: conf/config.yaml


conda: "requirements.yaml"  # Path: envs/conda.yaml


envvars:
    "CENSUS_API_KEY",


# read hydra config from initialize API
with hydra.initialize(config_path="conf", version_base=None):
    # here we set the data path for real hospitazation training data
    processing_cfg = hydra.compose(config_name="config")


# make sure data locations exist / user can set them to
# symlinks separately if preferred
data_dir = processing_cfg.data_dir
os.makedirs(f"{data_dir}/raw", exist_ok=True)
os.makedirs(f"{data_dir}/processed", exist_ok=True)

filters = ["65000", "all"]


rule all:
    input:
        expand(
            data_dir + "/processed/endogenous_states_actions_{filter}.parquet",
            filter=filters,
        ),
        expand(
            data_dir + "/processed/exogenous_states_{filter}.parquet",
            filter=filters,
        ),
        expand(
            data_dir + "/processed/bspline_basis_{filter}.parquet",
            filter=filters,
        ),
        expand(
            data_dir + "/processed/confounders_{filter}.parquet",
            filter=filters,
        ),


rule merge_state_actions:
    input:
        expand(
            data_dir + "/processed/alerts/{state}.parquet",
            state=config["states"],
        ),
        data_dir + "/processed/heatmetrics_{filter}.parquet",
    output:
        data_dir + "/processed/exogenous_states_{filter}.parquet",
        data_dir + "/processed/endogenous_states_actions_{filter}.parquet",
        data_dir + "/processed/budget_{filter}.parquet",
        data_dir + "/processed/bspline_basis_{filter}.parquet",
    log:
        "logs/merge_state_actions_{filter}.log",
    shell:
        "python merge_state_actions.py county_filter={wildcards.filter} &> {log}"


rule confounders:
    output:
        data_dir + "/processed/confounders_{filter}.parquet",
    log:
        "logs/confounders_{filter}.log",
    shell:
        f"""
        python confounders.py \
            census_api_key={os.environ['CENSUS_API_KEY']} county_filter={{wildcards.filter}} \
            &> {{log}}
        """


rule heatmetrics:
    input:
        data_dir + "/processed/confounders_{filter}.parquet",
    output:
        data_dir + "/processed/heatmetrics_{filter}.parquet",
    log:
        "logs/heatmetrics_{filter}.log",
    shell:
        "python heatmetrics.py county_filter={wildcards.filter}  &> {log}"


rule alerts:
    output:
        data_dir + "/processed/alerts/{state}.parquet",
    log:
        "logs/alerts_{state}.log",
    shell:
        "python heatalerts.py alerts.state={wildcards.state} &> {log}"
